#!/usr/bin/env python3
"""
doc_meta_enforcer.py

Automates:
- Adding AI generation note into Document Control sections
- Linking internal document references
- Generating stub documents if referenced but missing

Usage:
  # Check only (CI) - ATA_02 only
  python tools/ci/doc_meta_enforcer.py --check

  # Auto-fix locally - ATA_02 only
  python tools/ci/doc_meta_enforcer.py --fix

  # Retrofit entire OPT-IN_FRAMEWORK directory
  python tools/ci/doc_meta_enforcer.py --fix --scope entire

  # Check entire repository
  python tools/ci/doc_meta_enforcer.py --check --scope full
"""

import argparse
import pathlib
import re
import sys
from typing import List, Tuple

# This script lives in repo_root/tools/ci/
REPO_ROOT = pathlib.Path(__file__).resolve().parents[2]

# Default to ATA_02 for backward compatibility, but can scan entire framework
DEFAULT_DOC_ROOT = (
    REPO_ROOT
    / "OPT-IN_FRAMEWORK"
    / "I-INFRASTRUCTURES"
    / "ATA_02-OPERATIONS_INFORMATION"
)

ENTIRE_FRAMEWORK_ROOT = REPO_ROOT / "OPT-IN_FRAMEWORK"

AI_LINE = (
    "- Generated by: AI (prompted by Amedeo Pelliccia); "
    "pending approval by [Approver]"
)

# We treat these as "internal" docs that can be stubbed & linked
INTERNAL_EXTS = {".md", ".csv", ".json"}


def find_component_root(path: pathlib.Path, doc_root: pathlib.Path) -> pathlib.Path:
    """
    Given a file like
    .../02-11-00_AIRCRAFT_DIMENSIONS_GEOMETRY/07_V_AND_V/...
    return the component root
    .../02-11-00_AIRCRAFT_DIMENSIONS_GEOMETRY
    
    Also handles other OPT-IN_FRAMEWORK structures like:
    .../ATA_XX-COMPONENT_NAME/...
    """
    p = path
    while p != REPO_ROOT:
        # Match ATA chapter pattern: 02-11-00_NAME or ATA_XX-NAME
        if re.match(r"(\d{2}-\d{2}-\d{2}_.+|ATA_\d{2}-.+)", p.name):
            return p
        p = p.parent
    return doc_root


def ensure_ai_line_in_doc_control(text: str) -> Tuple[str, bool]:
    """
    Ensure Document Control section contains AI_LINE.
    Returns (new_text, changed?).
    """
    lines = text.splitlines()
    changed = False

    for i, line in enumerate(lines):
        if "Document Control" in line:
            # Scan following lines until blank or next header
            j = i + 1
            has_ai = False
            while j < len(lines) and lines[j].strip() and not lines[j].startswith("#"):
                if "Generated by:" in lines[j] or "Generated by AI" in lines[j]:
                    has_ai = True
                    break
                j += 1
            if not has_ai:
                lines.insert(i + 1, AI_LINE)
                changed = True
            break  # assume only one Document Control section

    return "\n".join(lines), changed


def find_internal_paths(text: str) -> List[str]:
    """
    Find internal file-like references such as:
      01_OVERVIEW/baseline_dimensions.json
      07_V_AND_V/DIMENSION_VERIFICATION/VER-02-11-001_Wingspan_Measurement.md

    Very simple heuristic: something with slashes + known extension.
    """
    pattern = r"(?P<path>\b[0-9]{2}_[A-Z0-9][A-Za-z0-9_/-]*/[^\s`\)]+?\.(?:md|csv|json))"
    return sorted(set(m.group("path") for m in re.finditer(pattern, text)))


def link_internal_paths(
    text: str, component_root: pathlib.Path
) -> Tuple[str, List[pathlib.Path], bool]:
    """
    Turn bare paths into markdown links if not already linked.
    Also collect paths that don't exist for possible stub generation.
    Returns (new_text, missing_paths, changed?).
    """
    missing: List[pathlib.Path] = []
    changed = False

    def repl(match: re.Match) -> str:
        nonlocal changed, missing
        path_str = match.group("path")

        # If already part of a markdown link, don't touch
        # e.g. [something](01_OVERVIEW/xxx.md)
        pre = text[max(0, match.start() - 2) : match.start()]
        if pre == "](":
            return path_str

        target = component_root / path_str
        if not target.exists():
            missing.append(target)

        changed = True
        return f"[{path_str}]({path_str})"

    pattern = r"(?P<path>\b[0-9]{2}_[A-Z0-9][A-Za-z0-9_/-]*/[^\s`\)]+?\.(?:md|csv|json))"
    new_text = re.sub(pattern, repl, text)
    return new_text, missing, changed


def create_stub(path: pathlib.Path) -> None:
    """
    Create a minimal stub document for missing internal references.
    """
    path.parent.mkdir(parents=True, exist_ok=True)
    ext = path.suffix.lower()

    if ext == ".md":
        title = path.stem.replace("_", " ")
        content = f"""# {title}

> Auto-generated placeholder document.
> Referenced from another document, but no content exists yet.

## Purpose

TBD – this document was created automatically because it was referenced but not present.

---

**Document Control:**
{AI_LINE}
- Version: 0.1
- Status: Draft – Auto-generated placeholder
- Last Updated: TBD
"""
        path.write_text(content, encoding="utf-8")
    elif ext == ".csv":
        content = "Field,Description\nTODO,Auto-generated placeholder CSV for referenced document\n"
        path.write_text(content, encoding="utf-8")
    elif ext == ".json":
        content = '{\n  "//": "Auto-generated placeholder JSON for referenced document"\n}\n'
        path.write_text(content, encoding="utf-8")
    else:
        # Shouldn't happen with current INTERNAL_EXTS, but guard anyway
        path.write_text("AUTO-GENERATED PLACEHOLDER\n", encoding="utf-8")


def process_file(path: pathlib.Path, fix: bool, doc_root: pathlib.Path) -> List[str]:
    """
    Process a single markdown file.
    Returns a list of issues (strings) if in check mode or if something was fixed.
    """
    text = path.read_text(encoding="utf-8")
    component_root = find_component_root(path, doc_root)

    issues: List[str] = []

    # 1) Document Control AI line
    new_text, ai_changed = ensure_ai_line_in_doc_control(text)
    if ai_changed:
        msg = f"{path.relative_to(REPO_ROOT)}: missing AI generation line in Document Control"
        issues.append(msg)
        if fix:
            text = new_text

    # 2) Link internal paths
    linked_text, missing_paths, links_changed = link_internal_paths(text, component_root)
    if links_changed:
        msg = f"{path.relative_to(REPO_ROOT)}: added markdown links for internal document references"
        issues.append(msg)
        if fix:
            text = linked_text

    # 3) Create stubs for missing references
    for missing in missing_paths:
        rel = missing.relative_to(REPO_ROOT)
        if missing.suffix.lower() in INTERNAL_EXTS:
            issues.append(f"{path.relative_to(REPO_ROOT)}: referenced missing internal document {rel}")
            if fix:
                create_stub(missing)
                issues.append(f"  -> created stub {rel}")

    if fix and (ai_changed or links_changed):
        path.write_text(text, encoding="utf-8")

    return issues


def main() -> int:
    parser = argparse.ArgumentParser(
        description="Enforce document metadata standards across the repository"
    )
    parser.add_argument(
        "--check",
        action="store_true",
        help="Check only; do not modify files or create stubs (CI mode).",
    )
    parser.add_argument(
        "--fix",
        action="store_true",
        help="Apply fixes in-place and create stubs for missing documents.",
    )
    parser.add_argument(
        "--scope",
        choices=["ata02", "entire", "full"],
        default="ata02",
        help=(
            "Scope of documents to process. "
            "'ata02': ATA_02-OPERATIONS_INFORMATION only (default, CI-friendly). "
            "'entire' or 'full': Entire OPT-IN_FRAMEWORK directory (retrofit mode)."
        ),
    )
    args = parser.parse_args()

    if args.check and args.fix:
        print("Use either --check or --fix, not both.", file=sys.stderr)
        return 2

    fix = args.fix
    check = args.check or not args.fix  # default to check if no flag

    # Determine scope
    if args.scope in ["entire", "full"]:
        doc_root = ENTIRE_FRAMEWORK_ROOT
        print(f"[doc-meta] Processing entire OPT-IN_FRAMEWORK directory...")
    else:
        doc_root = DEFAULT_DOC_ROOT
        print(f"[doc-meta] Processing ATA_02-OPERATIONS_INFORMATION directory...")

    all_issues: List[str] = []

    for md in doc_root.rglob("*.md"):
        # Skip hidden directories and .git
        if any(part.startswith('.') for part in md.parts):
            continue
        issues = process_file(md, fix=fix, doc_root=doc_root)
        all_issues.extend(issues)

    if check:
        if all_issues:
            print("[doc-meta] Issues found:")
            for msg in all_issues:
                print("  -", msg)
            return 1
        else:
            print("[doc-meta] OK – all docs compliant.")
            return 0

    # fix mode
    if all_issues:
        print("[doc-meta] Applied fixes:")
        for msg in all_issues:
            print("  -", msg)
    else:
        print("[doc-meta] Nothing to fix.")
    return 0


if __name__ == "__main__":
    sys.exit(main())
