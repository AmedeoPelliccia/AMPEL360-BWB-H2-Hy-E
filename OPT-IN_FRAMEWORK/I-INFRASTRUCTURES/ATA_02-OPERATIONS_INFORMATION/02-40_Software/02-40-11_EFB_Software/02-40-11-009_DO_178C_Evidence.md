# 02-40-11-009 — DO-178C Evidence

## Purpose

This document defines the **structure, content, and repository organization** of the **DO-178C certification evidence** associated with the AMPEL360 **EFB App** (`02-40-11_EFB_Software`).

It provides:

- A **canonical layout** for all planning, development, verification, configuration management (CM), and quality assurance (QA) artefacts.
- A description of **traceability mechanisms** between requirements, design, code, tests, and operational usage.
- The mapping between **DO-178C objectives** and:
  - EFB-specific modules (Performance, W&B, Weather, Documents, etc.).
  - Evidence stored in the AMPEL360 repository and linked storages.
- Guidance for **SOI (Stage of Involvement) reviews** and authority-facing evidence packaging.

This document is the **entry point** for any audit, internal review, or certification activity related to EFB software DO-178C compliance.

---

## Scope

### In Scope

- DO-178C **evidence model** and directory structure for:
  - `02-40-11_EFB_Software` application.
  - Related libraries and components that are integral to the EFB.
- Evidence types for:
  - Planning data (PSAC, SDP, SVP, SCMP, SQAP, etc.).
  - Development data (requirements, design, code, models).
  - Verification data (plans, procedures, results, coverage).
  - CM and QA records.
  - Traceability matrices and compliance summaries.
- Alignment with:
  - `02-40-42_Testing_QA/`
  - `02-90-12_Certification_Documentation_Schemas/`
  - `02-90-01_Database_Schemas/` and `02-90-02_API_Specifications/` where relevant.

### Out of Scope

- Detailed **content** of each DO-178C artefact (e.g., full PSAC text).
- DO-254, DO-331, DO-332, DO-333 or other standard-specific supplements (they may be referenced but not fully defined here).
- Detailed **neural network / ML governance** (handled by ATA 95), except where EFB **consumes** outputs from NN services in an advisory capacity.

---

## 1. Applicability and Software Levels

### 1.1 Target Software Levels (Preliminary)

The EFB application contains multiple functional areas with potentially **different software levels** (DAL) depending on final safety assessment:

- **Performance and W&B modules:**
  - Candidate level: **B or C** (depending on final FHA/SSA and use-case: advisory vs. operationally binding).
- **Weather and documentation viewer modules:**
  - Candidate level: **C or D** (advisory, not sole means of compliance).
- **Supportive features** (settings, UI preferences, non-safety-critical analytics):
  - Typically **D**.

Final assignments are documented in:

- `02-40-11-009_DO_178C_Evidence.md` (this document, high-level view).
- Safety assessment and DAL justification documents under the relevant ATA 25/31/95 folders and certification plans.

### 1.2 Supplements and Additional Guidance

Where applicable, this evidence structure may leverage:

- **DO-178C core** for all software lifecycle aspects.
- Applicable supplements (DO-331 model-based, DO-333 formal methods, etc.) if adopted later; references would be maintained in:
  - `02-90-12-001_DO_178C_Artifact_Schema.md`
  - Planning documents (PSAC, SDP, SVP).

---

## 2. Evidence Package Structure

All DO-178C-related artefacts for the EFB are organized under:

- `02-40_Software/02-40-11_EFB_Software/ASSETS/Certification/`
- With additional support from:
  - `02-40-42_Testing_QA/`
  - `02-90-12_Certification_Documentation_Schemas/`

### 2.1 Top-Level Files (EFB DO-178C Package)

Typical top-level artefacts:

- `ASSETS/Certification/02-40-11-A-501_DO_178C_Package.pdf`
- `ASSETS/Certification/02-40-11-A-502_Test_Coverage_Report.html`
- `ASSETS/Certification/02-40-11-A-503_Traceability_Matrix.xlsx`
- `ASSETS/Certification/02-40-11-A-504_Compliance_Checklist.xlsx`

These top-level files:

- Provide **human-readable** overviews (PDF/HTML) for authorities and internal reviewers.
- Are generated and/or assembled from **source-controlled artefacts** in the repository.

---

## 3. Planning Data

Planning data defines **how** EFB software is developed, verified, managed and certified.

### 3.1 Plan for Software Aspects of Certification (PSAC)

- File(s) (illustrative):
  - `ASSETS/Certification/Planning/02-40-11-P-001_PSAC_EFB.md`
- Content:
  - Applicable systems and configurations.
  - DAL allocations for each EFB module.
  - Use of COTS tools and operating environments.
  - Intended use of model-based methods, test automation, and formal methods (if any).
  - References to:
    - `02-40-00-001_Software_Architecture_Overview.md`
    - `02-40-11-001_EFB_App_Architecture.md`

### 3.2 Software Development Plan (SDP)

- `ASSETS/Certification/Planning/02-40-11-P-002_SDP_EFB.md`
- Describes:
  - Lifecycle model (e.g., V-model with incremental baselines).
  - Requirements management, design, implementation and integration processes.
  - Reference to:
    - `02-40-00-004_Software_Development_Standards.md`
    - `02-40-51_Documentation/`

### 3.3 Software Verification Plan (SVP)

- `ASSETS/Certification/Planning/02-40-11-P-003_SVP_EFB.md`
- Defines:
  - Verification strategy per DO-178C objective set and DAL.
  - Unit, integration, and system-level test approaches for EFB.
  - Code coverage expectations and tools (e.g., statement/decision coverage).
  - Link to:
    - `02-40-42_Testing_QA/`
    - `02-90-12-002_Test_Report_Templates.md`

### 3.4 Software Configuration Management Plan (SCMP)

- `ASSETS/Certification/Planning/02-40-11-P-004_SCMP_EFB.md`
- Content:
  - Configuration identification rules (tags, branches, baselines).
  - Configuration control (CRs, PRs, approval workflows).
  - Baseline and release guidelines for EFB builds.
  - Integration with:
    - Repository structure (`AMPEL360-BWB-H2-Hy-E`).
    - CI/CD pipelines (`02-40-41_DevOps_Infrastructure`).

### 3.5 Software Quality Assurance Plan (SQAP)

- `ASSETS/Certification/Planning/02-40-11-P-005_SQAP_EFB.md`
- Content:
  - QA organization, independence criteria, and activities.
  - Audits (process, artefact and code audits).
  - Review records and sign-off expectations.

---

## 4. Development Data

Development data are artefacts produced during requirements, design, and implementation phases.

### 4.1 Requirements

- **High-Level Requirements (HLR):**
  - EFB-level operational and functional requirements.
  - Located in:
    - `02-40-11_xxx` module documents (Performance, W&B, Weather, Docs).
    - Dedicated requirement files (e.g., `02-40-11-RQ-xxx_*.md`) where needed.
- **Low-Level Requirements (LLR):**
  - Detailed EFB component or function requirements.
  - Captured in:
    - Module-specific design docs (`02-40-11-004_Performance_Module.md`, etc.).
    - API contracts (`02-90-02_API_Specifications`).

All requirements must be:

- **Uniquely identified** (e.g., `EFB-PRF-RQ-001`).
- Traceable to:
  - Higher-level system requirements (aircraft-level, ops-level).
  - Corresponding test cases and results.

### 4.2 Design Data

- Architecture-level design:
  - `02-40-11-001_EFB_App_Architecture.md`
- Module-level design:
  - `02-40-11-00x_*.md` for Performance, W&B, Weather, Docs, etc.
- Data models and schemas:
  - `02-90-01_Database_Schemas/`
  - `02-90-02_API_Specifications/`
- Any model-based artefacts (if used):
  - Stored under module-specific `ASSETS/` directories with versioning and references in design docs.

### 4.3 Source Code and Build Data

- Source:
  - `ASSETS/Source_Code/ios_app/`
  - Shared logic in `ASSETS/Source_Code/shared_logic/`
- Build scripts and configuration:
  - Under `02-40-41_DevOps_Infrastructure/ASSETS/CI_CD/`
- Required traceability:
  - From LLR → code units/classes/functions → tests (unit/integration).

---

## 5. Verification Data

Verification data demonstrates that development outputs satisfy DO-178C objectives.

### 5.1 Verification Planning and Procedures

- Test strategies and templates:
  - `02-40-42-001_Testing_Strategy.md`
  - Templates in `02-90-12-002_Test_Report_Templates.md`
- EFB-specific test plans and procedures:
  - `02-40-42/Test_Suites/` (unit, integration, E2E).

### 5.2 Test Cases, Results, and Problem Reports

- Test cases and scripts:
  - Unit tests:
    - `ASSETS/Source_Code/unit_tests/`
  - Integration/E2E:
    - `02-40-42/Test_Suites/integration_tests/`
    - `02-40-42/Test_Suites/e2e_tests/`
- Results:
  - `02-40-42/Test_Reports/02-40-42-A-101_Coverage_Report.html`
  - Additional performance, load, and robustness tests as PDFs/HTML.
- Problem/Change Reports (PR/CR):
  - Stored in a dedicated location, e.g.:
    - `ASSETS/Certification/QA/Problem_Reports/`
  - Linked to:
    - Requirements, design, code changes and retest evidence.

### 5.3 Structural Coverage

- Coverage analysis reports:
  - Included in:
    - `02-40-42-A-101_Coverage_Report.html` (or EFB-specific variant).
  - Coverage level:
    - According to DAL (e.g., statement/decision coverage for Level C; MC/DC for Level B, if required).
- Mapping:
  - Test cases ↔ executed code elements ↔ requirements.

---

## 6. Configuration Management (CM) and Quality Assurance (QA) Records

### 6.1 CM Records

- CM artefacts include:
  - Baseline definitions and release notes.
  - Change logs and approval records.
- Typical storage:
  - `02-40-52_Lifecycle_Management/`
  - `ASSETS/Certification/CM_Records/`
- Integration:
  - With version control system (Git tags, branches).
  - With CI/CD pipelines for reproducible builds.

### 6.2 QA Records

- QA records:
  - Audit reports, non-conformity reports and closure evidence.
  - Stored in:
    - `ASSETS/Certification/QA/`
- Content:
  - Evidence that planned QA activities (per SQAP) have been executed.
  - Audit checklists and findings.
  - Corrective action records and verification.

---

## 7. Traceability Model

### 7.1 Traceability Objectives

The traceability model must allow:

- **Top-down**:
  - From aircraft/system-level requirements → EFB HLR → LLR → code → tests.
- **Bottom-up**:
  - From test cases and code back to LLR/HLR and higher-level requirements.
- **Sideways**:
  - Between requirements and associated:
    - Safety assessments.
    - Problem reports.
    - Configuration items.

### 7.2 Traceability Artefacts

- Master traceability matrix:
  - `ASSETS/Certification/02-40-11-A-503_Traceability_Matrix.xlsx`
- Additional cross-references:
  - Requirements trace CSV/YAML files in relevant EFB module folders.
  - Certification schemas:
    - `02-90-12-A-001_Requirements_Schema.json`
    - `02-90-12-A-002_Test_Case_Schema.json`
    - `02-90-12-A-003_Traceability_Matrix_Template.xlsx`

### 7.3 Integration with ML / NN (if applicable)

Where the EFB consumes **advisory outputs** from NN-based services (ATA 95):

- Inputs/outputs must be:
  - Clearly defined in API specs (`02-90-02_API_Specifications`).
  - Classified as **advisory**, with ultimate authority on the crew.
- Traceability must capture:
  - Which EFB features depend on which external NN services.
  - Constraints, fallbacks, and failure behaviour for unavailable or low-confidence NN outputs.

---

## 8. SOI Reviews and Authority Interaction

### 8.1 SOI 1–4 Preparation

This evidence structure is designed to support **Stage of Involvement (SOI)** reviews:

- **SOI 1 – Planning:**
  - PSAC, SDP, SVP, SCMP, SQAP.
- **SOI 2 – Development:**
  - Requirements and design documents, coding standards, architecture.
- **SOI 3 – Verification:**
  - Test plans, procedures, results, coverage and problem reports.
- **SOI 4 – Final:**
  - Configuration index, compliance summary, final trace matrix, production baseline.

### 8.2 Compliance Summary

- Consolidated compliance summary:
  - `ASSETS/Certification/02-40-11-A-504_Compliance_Checklist.xlsx`
- Content:
  - For each DO-178C objective (per DAL):
    - Evidence location.
    - Status (Planned, In progress, Complete).
    - Notes or deviations, if any.

---

## 9. Evidence Maintenance and Evolution

### 9.1 Change Management

- Every change affecting:
  - Requirements.
  - Design.
  - Code.
  - Verification artefacts.
- Must be:
  - Logged via CR/PR process.
  - Reflected in updated:
    - Traceability matrix.
    - Test impact analysis.
    - CM/QA records.

### 9.2 Baseline and Release Management

- Major baselines (e.g., **EFB v1.0, v1.1…**) are:
  - Tagged in version control.
  - Associated with:
    - A frozen set of certification artefacts.
    - A snapshot of `02-40-11-A-501_DO_178C_Package.pdf` and related files.

### 9.3 Archiving

- Older baselines must remain:
  - **Reproducible**, with build and environment instructions under:
    - `02-40-41_DevOps_Infrastructure/`
  - Accessible for:
    - Post-incident analysis.
    - Regulatory inquiries.

---

## References

- [02-40-11 EFB Software README](README.md)  
- [02-40-00-001 Software Architecture Overview](../02-40-00-001_Software_Architecture_Overview.md)  
- [02-40-00-004 Software Development Standards](../02-40-00-004_Software_Development_Standards.md)  

Related:

- `../02-40-42_Testing_QA/README.md`  
- `../02-40-41_DevOps_Infrastructure/README.md`  
- `../../02-60_Storages/README.md`  
- `../../02-90_Tables_Schemas_Diagrams/02-90-12_Certification_Documentation_Schemas/`  

---

## Document Control

- **Generated with the assistance of AI (GitHub Copilot / ChatGPT), prompted by Amedeo Pelliccia**.  
- **Status**: DRAFT – Initial DO-178C evidence structure for EFB application.  
- **Human approver**: _[to be completed]_.  
- **Repository**: `AMPEL360-BWB-H2-Hy-E`  
- **Last AI update**: _2025-11-21_.  

---

**End of Document**
```

